### 目标检测one-stage和two-stage网络的区别

one-stage网络以yolo系列网络为代表的，two-stage网络以faster-rcnn为代表

#### 主要区别

\* one-stage网络速度要快很多

\* one-stage网络的准确性要比two-stage网络要低

#### 为什么one网络速度要快很多？

首先，one-stage网络生成的anchor只是一个逻辑结构，或者只是一个数据快，只需要对这个数据块进行分类和回归就可以。不会像two-stage网络那样，

生成的anchor框会映射到feature map的区域（rcnn除外），然后将该区域重新输入到全联接层进行分类和回归，每个anchor映射的区域都要进行这样的分类，所以它非常耗时

### 为什么one网络的准确率要比two网络要低？

我们再来看第二点，为什么two-stage网络要准确些，我们来看rcnn，它是首先在原图上生成若干个候选区域，这个候选区域表示可能会是目标的候选区域，注意，这样的候选区域肯定不会特别多，假如我一张图像是100x100的，它可能会生成2000个候选框，然后再把这些候选框送到分类和回归网络中进行分类和回归，fast-rcnn其实差不多，只不过它不是最开始将原图的这些候选区域送到网络中，而是在最后一个feature map将这个候选区域提出来，进行分类和回归，它可能最终进行分类和回归的候选区域也只有2000多个并不多，再来看faster-rcnn，虽然faster-rcnn它最终一个feature map它是每个像素点产生9个ancor，那么100x100假如到最终的feature map变成了26x26了，那么生成的ancor就是26x26x9 = 6084个，虽然看似很多，但是其实它在rpn网络结束后，它会不断的筛选留下2000多个，然后再从2000多个中筛选留下300多个，然后再将这300多个候选区域送到最终的分类和回归网络中进行训练，所以不管是rcnn还是fast-rcnn还是faster-rcnn，它们最终进行训练的ancor其实并不多，几百到几千，不会存在特别严重的正负样本不均衡问题，但是我们再来看yolo系列网络，就拿yolo3来说吧，它有三种尺度，13x13，26x26，52x52，每种尺度的每个像素点生成三种ancor，那么它最终生成的ancor数目就是(13x13+26x26+52x52)*3 = 10647个ancor，而真正负责预测的可能每种尺度的就那么几个，假如一张图片有3个目标，那么每种尺度有三个ancor负责预测，那么10647个ancor中总共也只有9个ancor负责预测，也就是正样本，其余的10638个ancor都是背景ancor，这存在一个严重的正负样本失衡问题，虽然位置损失，类别损失，这10638个ancor不需要参与，但是目标置信度损失，背景ancor参与了，因为总的损失 = 位置损失 + 目标置信度损失 + 类别损失，所以背景ancor对总的损失有了很大的贡献，但是我们其实不希望这样的，我们更希望的是非背景的ancor对总的损失贡献大一些，这样不利于正常负责预测ancor的学习，而two-stage网络就不存在这样的问题，two-stage网络最终参与训练的或者计算损失的也只有2000个或者300个，它不会有多大的样本不均衡问题，不管是正样本还是负样本对损失的贡献几乎都差不多，所以网络会更有利于负责预测ancor的学习，所以它最终的准确性肯定要高些



总结下：

说了那么多，用一个句话总结，one-stage网络最终学习的anchor有很多，但是只有少数ancor对最终网络的学习是有利的，而大部分ancor对最终网络的学习都是不利的，这部分的ancor很大程度上影响了整个网络的学习，拉低了整体的准确率；而two-stage网络最终学习的ancor虽然不多，但是背景ancor也就是对网络学习不利的ancor也不会特别多，它虽然也能影响整体的准确率，但是肯定没有one-stage影响得那么严重，所以它的准确率比one-stage肯定要高。



#### 解决one-stage网络背景anchor过多导致的不均衡问题方案

\* 采用focal-loss，将目标置信度这部分的损失换成focal-loss，具体如下：

\* 增大非背景anchor的数量

某个像素点生成的三个ancor，与真实grundtruth重合最大那个负责预测，它负责计算位置损失、目标置信度损失、类别损失，这些不管，它还有另外两个ancor，虽然另外两个ancor不是与真实grundtruth重合最大，但是只要重合大于某个阀值比如大于0.7，我就认为它是非背景ancor，但注意它只计算目标置信度损失，位置和类别损失不参与计算，而小于0.3的我直接不让它参与目标置信度损失的计算，实现也就是将它的权重置0，这个思想就类似two-stage网络那个筛选机制，从2000多个ancor中筛选300个参与训练或者计算目标置信度损失，相当于我把小于0.3的ancor我都筛选掉了，让它不参与损失计算

\* 设置权重

在目标置信度损失计算时，将背景ancor的权重设置得很小，非背景ancor的权重设置得很大