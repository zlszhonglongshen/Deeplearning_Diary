### .深度学习检测小目标常用的方法

#### 参考链接

* [我们是如何改进YOLOv3进行红外小目标检测的](https://www.cnblogs.com/pprp/p/13644068.html)

* 修改Anchor

* 在图片中任意位置复制小目标，通常是复制1-2次

* 修改backbone

  修改backbone我们也从几个方面入手，分为注意力模块、即插即用模块、修改FPN、修改激活函数、用成熟的网络替换backbone和SPP系列。

  * 1.注意力模块

    https://github.com/pprp/SimpleCVReproduction

    模块主要用：SE，CBAM等。在FPN的三个分支上各加了一个CBAM。

  * 2.即插即用模块

    注意力模块也属于即插即用模块，这部分就说的是非注意力模块的部分如 FFM、ASPP、PPM、Dilated Conv、SPP、FRB、CorNerPool、DwConv、ACNet等，效果还可以，但是没有超过当前最好的结果。

  * 3.修改FPN

  * 4.修改激活函数

    yolo默认的使用的激活函数是leakly-relu，激活函数方面使用了mish，效果并咩有提升

  * 5.用成熟的网络替换backbone

    这里使用了ResNet10(第三方实现)、DenseNet、BBuf修改的DenseNet、ENet、VOVNet(自己改的)、csresnext50-panet(当时AB版darknet提供的)、PRN(作用不大)等网络结构。

    当前最强的网络是dense-v3-tiny-spp，也就是BBuf修改的Backbone+原汁原味的SPP组合的结构完虐了其他模型，在测试集上达到了mAP@0.5=0.932、F1=0.951的结果。

  * 6.SPP系列

    实际上SPP就是多个空间池化的组合，对不同输出尺度采用不同的划窗大小和步长以确保输出尺度相同，同时能够融合金字塔提取出的多种尺度特征，能够提取更丰富的语义信息。常用于多尺度训练和目标检测中的RPN网络。

  * 7.修改loss

    loss方面尝试了focal loss，但是经过调整alpha和beta两个参数，不管默认的还是自己慢慢调参，网络都无法收敛

    ## 小目标检测相关技巧总结

    小目标定义：在COCO数据集中，面积小于32*32的物体被认为是小物体。

    在coco数据集中，小目标的数量更多，具体为：

    41% of objects are small (area < 322)
     34% are medium (322 < area < 962)
     24% are large (area > 962)
     area的计算方法：像素点的个数。

    小目标难以检测的原因：分辨率低，图像模糊，携带的信息少。因此所导致特征表达能力弱，也就是在提取特征的过程中，能提取到的特征非常少，这不利于我们对小目标的检测。

    

#### 如何解决小目标检测问题？

* 1：由于小目标面积太小，可以放大图片后再做检测，也就是在尺寸上做文章。如FPN

* 在Anchor上做文章(Faster Rcnn，SSD, FPN都有各自的anchor设计)，anchor在设置方面需要考虑三个因素：

  **anchor的密度：**由检测所用feature map的stride决定，这个值与前景阈值密切相关。

  **anchor的范围：**RetinaNet中是anchor范围是32~512，这里应根据任务检测目标的范围确定，按需调整anchor范围，或目标变化范围太大如MS COCO，这时候应采用多尺度测试。

  **anchor的形状数量：**RetinaNet每个位置预测三尺度三比例共9个形状的anchor，这样可以增加anchor的密度，但stride决定这些形状都是同样的滑窗步进，需考虑步进会不会太大，如RetinaNet框架前景阈值是0.5时，一般anchor大小是stride的4倍左右。

* 在ROI POOLing上做文章。



